{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94439f0f",
   "metadata": {},
   "source": [
    "Q1: K-Fold Cross Validation for Multiple Linear Regression (Least Squares Fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20efaa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "data=pd.read_csv(\"USA_Housing.csv\")\n",
    "X=data.drop(columns=['Price']).values\n",
    "y=data['Price'].values.reshape(-1, 1)\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "kf=KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "best_beta=None\n",
    "best_r2=-np.inf\n",
    "print(\"5-Fold Cross Validation Results\\n\")\n",
    "fold = 1\n",
    "for train_index,test_index in kf.split(X_scaled):\n",
    "    X_train,X_test=X_scaled[train_index],X_scaled[test_index]\n",
    "    y_train,y_test=y[train_index],y[test_index]\n",
    "    X_train_b=np.c_[np.ones((X_train.shape[0],1)),X_train]\n",
    "    X_test_b=np.c_[np.ones((X_test.shape[0],1)),X_test]\n",
    "    beta=np.linalg.inv(X_train_b.T@X_train_b)@(X_train_b.T@ y_train)\n",
    "    y_pred = X_test_b @ beta\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\" Beta Shape: {beta.shape}\")\n",
    "    print(f\"R2 Score : {r2:.4f}\\n\")\n",
    "    if r2>best_r2:\n",
    "        best_r2=r2\n",
    "        best_beta=beta\n",
    "    fold+=1\n",
    "print(\"Best R2 Score from CV:\",best_r2)\n",
    "print(\"Best Beta Matrix:\\n\",best_beta)\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=0.3,random_state=42)\n",
    "\n",
    "\n",
    "X_train_b=np.c_[np.ones((X_train.shape[0],1)),X_train]\n",
    "X_test_b=np.c_[np.ones((X_test.shape[0],1)),X_test]\n",
    "\n",
    "\n",
    "beta_final=np.linalg.inv(X_train_b.T@X_train_b)@(X_train_b.T@y_train)\n",
    "\n",
    "\n",
    "y_pred_final=X_test_b@beta_final\n",
    "\n",
    "\n",
    "final_r2=r2_score(y_test,y_pred_final)\n",
    "\n",
    "print(\"\\nFinal Model (70/30 Split)\")\n",
    "print(\"Final Beta Matrix:\\n\",beta_final)\n",
    "print(\"Final R2 Score on Test Data:\",final_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c03e638",
   "metadata": {},
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e46c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"USA_Housing.csv\")\n",
    "\n",
    "X = data.drop(columns=['Price']).values\n",
    "y = data['Price'].values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_scaled = np.c_[np.ones((X_scaled.shape[0], 1)), X_scaled]\n",
    "\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.30, random_state=42\n",
    ")\n",
    "\n",
    "# Now split 70% into 56% (train) and 14% (val)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.20, random_state=42\n",
    ")  # 0.20 of 70% = 14%\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\" Train:\", X_train.shape, y_train.shape)\n",
    "print(\" Validation:\", X_val.shape, y_val.shape)\n",
    "print(\" Test:\", X_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "def gradient_descent(X, y, lr, iters):\n",
    "    m, n = X.shape\n",
    "    beta = np.zeros((n, 1))\n",
    "\n",
    "    for _ in range(iters):\n",
    "        y_pred = X @ beta\n",
    "        error = y_pred - y\n",
    "        grad = (1/m) * (X.T @ error)\n",
    "        beta -= lr * grad\n",
    "    return beta\n",
    "\n",
    "\n",
    "learning_rates = [0.001, 0.01, 0.1, 1]\n",
    "iters = 1000\n",
    "\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    beta = gradient_descent(X_train, y_train, lr, iters)\n",
    "\n",
    "\n",
    "    y_val_pred = X_val @ beta\n",
    "    r2_val = r2_score(y_val, y_val_pred)\n",
    "\n",
    "    y_test_pred = X_test @ beta\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    results.append((lr, beta, r2_val, r2_test))\n",
    "\n",
    "    print(f\"Learning Rate: {lr}\")\n",
    "    print(f\"  Validation R2: {r2_val:.4f}\")\n",
    "    print(f\"  Test R2      : {r2_test:.4f}\\n\")\n",
    "\n",
    "best_result = max(results, key=lambda x: x[2])\n",
    "\n",
    "best_lr, best_beta, best_r2_val, best_r2_test = best_result\n",
    "\n",
    "print(\"------ Best Model ------\")\n",
    "print(\"Best Learning Rate:\", best_lr)\n",
    "print(\"Best Coefficients (Beta):\\n\", best_beta)\n",
    "print(\"Best Validation R2:\", best_r2_val)\n",
    "print(\"Corresponding Test R2:\", best_r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a3878d",
   "metadata": {},
   "source": [
    "Car Price Prediction using Linear Regression and PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecff666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "columns = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\", \"num_doors\",\n",
    "           \"body_style\", \"drive_wheels\", \"engine_location\", \"wheel_base\", \"length\", \"width\",\n",
    "           \"height\", \"curb_weight\", \"engine_type\", \"num_cylinders\", \"engine_size\",\n",
    "           \"fuel_system\", \"bore\", \"stroke\", \"compression_ratio\", \"horsepower\", \"peak_rpm\",\n",
    "           \"city_mpg\", \"highway_mpg\", \"price\"]\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
    "data = pd.read_csv(url, names=columns)\n",
    "\n",
    "\n",
    "data = data.replace(\"?\", np.nan)\n",
    "\n",
    "\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object':\n",
    "\n",
    "        data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "    else:\n",
    "\n",
    "        data[col] = pd.to_numeric(data[col], errors=\"coerce\")  # convert to numeric first\n",
    "        data[col].fillna(data[col].mean(), inplace=True)\n",
    "\n",
    "\n",
    "data = data.dropna(subset=['price'])\n",
    "data['price'] = data['price'].astype(float)\n",
    "\n",
    "\n",
    "door_map = {\"two\": 2, \"four\": 4}\n",
    "cyl_map = {\"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5, \"six\": 6, \"eight\": 8, \"twelve\": 12}\n",
    "data['num_doors'] = data['num_doors'].map(door_map)\n",
    "data['num_cylinders'] = data['num_cylinders'].map(cyl_map)\n",
    "\n",
    "\n",
    "data = pd.get_dummies(data, columns=[\"body_style\", \"drive_wheels\"], drop_first=True)\n",
    "\n",
    "for col in [\"make\", \"aspiration\", \"engine_location\", \"fuel_type\"]:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "\n",
    "data['fuel_system'] = data['fuel_system'].apply(lambda x: 1 if 'pfi' in x else 0)\n",
    "\n",
    "data['engine_type'] = data['engine_type'].apply(lambda x: 1 if 'ohc' in x else 0)\n",
    "\n",
    "\n",
    "X = data.drop(columns=['price']).values\n",
    "y = data['price'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "r2_original = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Performance with original features:\")\n",
    "print(\" R2 Score:\", r2_original)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
    "\n",
    "reg_pca = LinearRegression()\n",
    "reg_pca.fit(X_train_pca, y_train_pca)\n",
    "\n",
    "y_pred_pca = reg_pca.predict(X_test_pca)\n",
    "r2_pca = r2_score(y_test_pca, y_pred_pca)\n",
    "\n",
    "print(\"\\nPerformance with PCA-reduced features:\")\n",
    "print(\" R2 Score:\", r2_pca)\n",
    "\n",
    "\n",
    "if r2_pca > r2_original:\n",
    "    print(\"\\n✅ PCA improved performance!\")\n",
    "else:\n",
    "    print(\"\\n❌ PCA did not improve performance.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
